{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Numpy will be used for Linear Algebra\n",
    "import numpy as np\n",
    "\n",
    "# Pandas will be used for DataFrames\n",
    "import pandas as pd\n",
    "# Display all Columns \n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "# Matplotlib for Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "# Display plots in notebook\n",
    "%matplotlib inline\n",
    "\n",
    "# Seaborn for easier Visualization\n",
    "import seaborn as sns\n",
    "# Change color scheme\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "# Sys for size of Dataset\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sklearn Packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import r2_score and mean_absolute_error functions\n",
    "from sklearn.metrics import r2_score \n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# Preprocessing\n",
    "from sklearn.preprocessing import StandardScaler,Imputer,PolynomialFeatures\n",
    "\n",
    "# Model Selection\n",
    "from sklearn.model_selection import train_test_split,cross_val_score,GridSearchCV,StratifiedKFold,RandomizedSearchCV\n",
    "from sklearn.linear_model import LinearRegression, Ridge,RidgeCV,Lasso,LassoCV,ElasticNet,ElasticNetCV\n",
    "\n",
    "# Tree\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "# Ensemble Methods\n",
    "from sklearn.ensemble import BaggingRegressor,RandomForestRegressor,AdaBoostRegressor,ExtraTreesRegressor,GradientBoostingRegressor\n",
    "\n",
    "# Pipelines\n",
    "from sklearn.pipeline import Pipeline,make_pipeline\n",
    "\n",
    "# Feature Selection\n",
    "from sklearn.feature_selection import VarianceThreshold,SelectKBest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load the Cleaned Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load training set into a pandas DataFrame\n",
    "train = pd.read_csv('../Datasets/cleaned_train.csv')\n",
    "\n",
    "# Load the testing set into a pandata DataFrame\n",
    "test = pd.read_csv(\"../Datasets/cleaned_test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Identify Features to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create a list that contains all the train columns names\n",
    "total_train_columns = train.columns.tolist() \n",
    "# Create a list that contains all the test columns names\n",
    "total_test_columns = test.columns.tolist() \n",
    "# Create a list that contains all the train and test columns names\n",
    "train_test_columns = train.columns.tolist() + test.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of total train columns: 190\n",
      "Length of total train columns: 174\n",
      "Length of total train columns: 364\n"
     ]
    }
   ],
   "source": [
    "# Print the length of the total train columns\n",
    "print(\"Length of total train columns:\",len(total_train_columns))\n",
    "# Print the length of the total test columns\n",
    "print(\"Length of total train columns:\",len(total_test_columns))\n",
    "# Print the length of the total train and test columns\n",
    "print(\"Length of total train columns:\",len(train_test_columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Only use columns that are contained in both training and testing set\n",
    "features_to_use = set.intersection(set(total_train_columns), set(total_test_columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# My features will not contain SalePrice or ID\n",
    "features_to_use = [col for col in features_to_use if (col != 'SalePrice') | (col != 'Id')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# DataFrame of Train and Test Features to use\n",
    "train_features = train.loc[:,features_to_use]\n",
    "test_features = test.loc[:,features_to_use]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SalePrice      1.000000\n",
       "OverallQual    0.806139\n",
       "ExterQual      0.717360\n",
       "GrLivArea      0.707484\n",
       "KitchenQual    0.693939\n",
       "GarageArea     0.653927\n",
       "TotalBsmtSF    0.650375\n",
       "Bath           0.646339\n",
       "1stFlrSF       0.631378\n",
       "BsmtQual       0.623871\n",
       "Name: SalePrice, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the top 25 absolute correlations\n",
    "train.corr()[\"SalePrice\"].apply(lambda x: abs(x)).sort_values(ascending = False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 3. Identify the Target Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Name the target variable\n",
    "target = train['SalePrice']\n",
    "\n",
    "# Create the log transformation of SalePrice\n",
    "target_log = np.log1p(train['SalePrice'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 4. Split and Scale the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A. Split into Train and Holdout set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# X will be all features in the training set excluding the target variable\n",
    "\n",
    "features = ['OverallQual', 'ExterQual','GrLivArea', 'KitchenQual', 'GarageArea','TotalBsmtSF','Bath','1stFlrSF']\n",
    "\n",
    "X = train_features[features]\n",
    "\n",
    "\n",
    "# Y will represent the target variable\n",
    "y = target_log\n",
    "\n",
    "# Train test split and use holdout set because we have an actual testing set\n",
    "X_train,X_holdout,y_train,y_holdout = train_test_split(X,y,random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### B. Scale the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Instantiate a StandardScaler object\n",
    "ss= StandardScaler()\n",
    "\n",
    "# Fit the Scaler on the training data\n",
    "ss.fit(X_train)\n",
    "\n",
    "# Transform training scaled and holdout scaled set\n",
    "X_train_scaled = ss.transform(X_train)\n",
    "X_holdout_scaled = ss.transform(X_holdout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function to calculate root mean square error for each model\n",
    "def rmse_cv(model):\n",
    "    rmse= np.sqrt(-cross_val_score(model, X_train_scaled, y_train, scoring=\"neg_mean_squared_error\", cv = 10))\n",
    "    return(rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Phase 1: Regularized Regression Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A. Simple Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression Scores: [0.77153486 0.87156474 0.85406164 0.85594019 0.79585892 0.88793453\n",
      " 0.83520211 0.63518659 0.79844283 0.87463172]\n",
      "Mean Score for Linear Regression: 0.8180358129807287\n",
      "The root mean square error for Linear Regression is: 0.1696\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Janet/anaconda3/lib/python3.6/site-packages/scipy/linalg/basic.py:1226: RuntimeWarning: internal gelsd driver lwork query error, required iwork dimension not returned. This is likely the result of LAPACK bug 0038, fixed in LAPACK 3.2.2 (released July 21, 2010). Falling back to 'gelss' driver.\n",
      "  warnings.warn(mesg, RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "lr = LinearRegression()\n",
    "lr.fit(X_train_scaled,y_train)\n",
    "print(\"Linear Regression Scores:\",cross_val_score(lr,X_train_scaled,y_train,cv=10))\n",
    "print(\"Mean Score for Linear Regression:\",np.mean(cross_val_score(lr,X_train_scaled,y_train,cv=10)))\n",
    "print(\"The root mean square error for Linear Regression is:\",rmse_cv(lr).mean().round(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Using the above features we can accurately guess the SalePrice 81% of the time based on the Linear Regression model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note: Since I will be using the same process I will write a function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def the_models_selection(model_name):\n",
    "    \"\"\"This function prints out the scores for the selected model\"\"\"\n",
    "    \n",
    "    # Instantiate the model\n",
    "    mn = model_name\n",
    "    \n",
    "    # Fit the model\n",
    "    mn_model = mn.fit(X_train_scaled,y_train)\n",
    "    \n",
    "    # Print out the name of Model being used\n",
    "    print(mn)\n",
    "    \n",
    "    # Score the model\n",
    "    mn_score_train = mn_model.score(X_train_scaled,y_train)\n",
    "    mn_score_test = mn_model.score(X_holdout_scaled,y_holdout)\n",
    "    \n",
    "    # Root Mean Squared Error\n",
    "    rmse= np.sqrt(-cross_val_score(mn, X_train_scaled, y_train, scoring=\"neg_mean_squared_error\", cv = 10))\n",
    "    \n",
    "    # Print out the scores mean\n",
    "    print(\"Train Score:\",mn_score_train)\n",
    "    print(\"Holdout Score:\",mn_score_train)\n",
    "    print(\"RMSE:\",rmse.mean().round(4))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### B. Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RidgeCV(alphas=array([1.00000e+00, 1.05956e+00, ..., 9.43788e+04, 1.00000e+05]),\n",
      "    cv=10, fit_intercept=True, gcv_mode=None, normalize=False,\n",
      "    scoring=None, store_cv_values=False)\n",
      "Train Score: 0.8250176341308525\n",
      "Holdout Score: 0.8250176341308525\n",
      "RMSE: 0.1694\n"
     ]
    }
   ],
   "source": [
    "the_models_selection(RidgeCV(alphas=np.logspace(0,5,200),cv=10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### C. Lasso Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LassoCV(alphas=None, copy_X=True, cv=10, eps=0.001, fit_intercept=True,\n",
      "    max_iter=1000, n_alphas=524, n_jobs=1, normalize=False, positive=False,\n",
      "    precompute='auto', random_state=None, selection='cyclic', tol=0.0001,\n",
      "    verbose=False)\n",
      "Train Score: 0.8253221037290417\n",
      "Holdout Score: 0.8253221037290417\n",
      "RMSE: 0.1697\n"
     ]
    }
   ],
   "source": [
    "the_models_selection(LassoCV(n_alphas=524,cv=10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### D. ElasticNet Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ElasticNetCV(alphas=None, copy_X=True, cv=10, eps=0.001, fit_intercept=True,\n",
      "       l1_ratio=array([0.01   , 0.04536, 0.08071, 0.11607, 0.15143, 0.18679, 0.22214,\n",
      "       0.2575 , 0.29286, 0.32821, 0.36357, 0.39893, 0.43429, 0.46964,\n",
      "       0.505  , 0.54036, 0.57571, 0.61107, 0.64643, 0.68179, 0.71714,\n",
      "       0.7525 , 0.78786, 0.82321, 0.85857, 0.89393, 0.92929, 0.96464,\n",
      "       1.     ]),\n",
      "       max_iter=1000, n_alphas=25, n_jobs=1, normalize=False,\n",
      "       positive=False, precompute='auto', random_state=None,\n",
      "       selection='cyclic', tol=0.0001, verbose=0)\n",
      "Train Score: 0.8251078427361072\n",
      "Holdout Score: 0.8251078427361072\n",
      "RMSE: 0.1695\n"
     ]
    }
   ],
   "source": [
    "the_models_selection(ElasticNetCV(l1_ratio=np.linspace(.01, 1.0, 29),n_alphas = 25,cv = 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Phase 2: Pipelines\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# X will be all features in the training set excluding the target variable\n",
    "\n",
    "features = ['OverallQual', 'ExterQual','GrLivArea', 'KitchenQual', 'GarageArea','TotalBsmtSF','Bath','1stFlrSF']\n",
    "\n",
    "X = train_features[features]\n",
    "\n",
    "\n",
    "# Y will represent the target variable\n",
    "y = target_log\n",
    "\n",
    "# Train test split and use holdout set because we have an actual testing set\n",
    "X_train,X_holdout,y_train,y_holdout = train_test_split(X,y,random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A. Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score: 0.8181212566485693\n",
      "Best Params: {'imp__strategy': 'mean', 'lasso__alpha': 0.005}\n"
     ]
    }
   ],
   "source": [
    "# Name variables\n",
    "imp = Imputer()\n",
    "ss = StandardScaler()\n",
    "lasso = Lasso(max_iter=5000)\n",
    "\n",
    "# Build Pipeline\n",
    "pipe = Pipeline([ \n",
    "    ('imp',imp),\n",
    "    ('ss', ss),\n",
    "    ('lasso', lasso)\n",
    "])\n",
    "\n",
    "# Hyperparameters\n",
    "params = {\n",
    "    'imp__strategy': ['mean', 'median','most_frequent'], # Tune hyperparameters for imputation strategy\n",
    "    'lasso__alpha': [0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1, 5, 10] # Tune hyperparameters for lasso alpha\n",
    "}\n",
    "\n",
    "# GridSearchCV model\n",
    "gs = GridSearchCV(pipe, param_grid=params, cv=10)\n",
    "gs.fit(X_train, y_train) # Fit and tune model\n",
    "\n",
    "print(\"Best Score:\",gs.best_score_) # Print Best Score\n",
    "print(\"Best Params:\",gs.best_params_) # Print Best parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### B. Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score: 0.8181659330479772\n",
      "Best Params: {'imp__strategy': 'mean', 'ridge__alpha': 10}\n"
     ]
    }
   ],
   "source": [
    "# Name variables\n",
    "imp = Imputer()\n",
    "ss = StandardScaler()\n",
    "ridge = Ridge(max_iter=5000)\n",
    "\n",
    "# Build Pipeline\n",
    "pipe = Pipeline([ \n",
    "    ('imp',imp),\n",
    "    ('ss', ss),\n",
    "    ('ridge', ridge)\n",
    "])\n",
    "\n",
    "# Hyperparameters\n",
    "params = {\n",
    "    'imp__strategy': ['mean', 'median','most_frequent'], # Tune hyperparameters for imputation strategy\n",
    "    'ridge__alpha': [0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1, 5, 10] # Tune hyperparameters for ridge alpha\n",
    "}\n",
    "\n",
    "# GridSearchCV model\n",
    "gs = GridSearchCV(pipe, param_grid=params, cv=10)\n",
    "gs.fit(X_train, y_train) # Fit and tune model\n",
    "\n",
    "print(\"Best Score:\",gs.best_score_) # Print Best Score\n",
    "print(\"Best Params:\",gs.best_params_) # Print Best parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### C. ElasticNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Name variables\n",
    "imp = Imputer()\n",
    "ss = StandardScaler()\n",
    "elasticnet = ElasticNet(max_iter=5000)\n",
    "\n",
    "# Build Pipeline\n",
    "pipe = Pipeline([ \n",
    "    ('imp',imp),\n",
    "    ('ss', ss),\n",
    "    ('elasticnet', elasticnet)\n",
    "])\n",
    "\n",
    "# Hyperparameters\n",
    "params = {\n",
    "    'imp__strategy': ['mean', 'median','most_frequent'], # Tune hyperparameters for imputation strategy\n",
    "    'elasticnet__alpha': [0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1, 5, 10], # Tune hyperparameters for elasticnet alpha\n",
    "    'elasticnet__l1_ratio': [0.1, 0.5, 0.09] # Tune hyperparameters for l1 ratio\n",
    "  \n",
    "}\n",
    "\n",
    "# GridSearchCV model\n",
    "gs = GridSearchCV(pipe, param_grid=params, cv=10)\n",
    "gs.fit(X_train, y_train) # Fit and tune model\n",
    "\n",
    "print(\"Best Score:\",gs.best_score_) # Print Best Score\n",
    "print(\"Best Params:\",gs.best_params_) # Print Best parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### D. RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Name variables\n",
    "imp = Imputer()\n",
    "ss = StandardScaler()\n",
    "randomforest = RandomForestRegressor(verbose = 1, n_jobs=-1)\n",
    "\n",
    "# Build Pipeline\n",
    "pipe = Pipeline([ \n",
    "    ('imp',imp),\n",
    "    ('ss', ss),\n",
    "    ('randomforest', randomforest)\n",
    "])\n",
    "\n",
    "# Hyperparameters\n",
    "params = {\n",
    "    'imp__strategy': ['mean', 'median','most_frequent'], # Tune hyperparameters for imputation strategy\n",
    "    'randomforest__n_estimators': [25,50,200], # Tune hyperparameters for n_estimators\n",
    "    'randomforest__max_depth': [80,50,200], # Tune hyperparameters for max_depth\n",
    "    'randomforest__max_features': ['auto','sqrt'] # Tune hyperparameters for max_features\n",
    "\n",
    "}\n",
    "\n",
    "# GridSearchCV model\n",
    "gs = GridSearchCV(pipe, param_grid=params, cv=10)\n",
    "gs.fit(X_train, y_train) # Fit and tune model\n",
    "\n",
    "print(\"Best Score:\",gs.best_score_) # Print Best Score\n",
    "print(\"Best Params:\",gs.best_params_) # Print Best parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### E. GradientBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Name variables\n",
    "imp = Imputer()\n",
    "ss = StandardScaler()\n",
    "gradientboost = GradientBoostingRegressor()\n",
    "\n",
    "# Build Pipeline\n",
    "pipe = Pipeline([ \n",
    "    ('imp',imp),\n",
    "    ('ss', ss),\n",
    "    ('gradientboost', gradientboost)\n",
    "])\n",
    "\n",
    "# Hyperparameters\n",
    "params = {\n",
    "    'imp__strategy': ['mean', 'median','most_frequent'], # Tune hyperparameters for imputation strategy\n",
    "    'gradientboost__n_estimators': [25,50,200], # Tune hyperparameters for n_estimators\n",
    "    'gradientboost__learning_rate': [.05,.2,.5], # Tune hyperparameters for learning_rate\n",
    "    'gradientboost__max_depth': [1,5], # Tune hyperparameters for max_depth\n",
    "}\n",
    "\n",
    "# GridSearchCV model\n",
    "gs = GridSearchCV(pipe, param_grid=params, cv=10)\n",
    "gs.fit(X_train, y_train) # Fit and tune model\n",
    "\n",
    "print(\"Best Score:\",gs.best_score_) # Print Best Score\n",
    "print(\"Best Params:\",gs.best_params_) # Print Best parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Phase 3: Use all features with best model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# X will be all features in the training set excluding the target variable\n",
    "X = train_features\n",
    "\n",
    "# Y will represent the target variable\n",
    "y = target_log\n",
    "\n",
    "# Train test split and use holdout set because we have an actual testing set\n",
    "X_train,X_holdout,y_train,y_holdout = train_test_split(X,y,random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Name variables\n",
    "imp = Imputer()\n",
    "ss = StandardScaler()\n",
    "randomforest = RandomForestRegressor(verbose = 1, n_jobs=-1)\n",
    "\n",
    "# Build Pipeline\n",
    "pipe = Pipeline([ \n",
    "    ('imp',imp),\n",
    "    ('ss', ss),\n",
    "    ('randomforest', randomforest)\n",
    "])\n",
    "\n",
    "# Hyperparameters\n",
    "params = {\n",
    "    'imp__strategy': ['mean', 'median','most_frequent'], # Tune hyperparameters for imputation strategy\n",
    "    'randomforest__n_estimators': [25,50,200], # Tune hyperparameters for n_estimators\n",
    "    'randomforest__max_depth': [80,50,200], # Tune hyperparameters for max_depth\n",
    "    'randomforest__max_features': ['auto','sqrt'] # Tune hyperparameters for max_features\n",
    "\n",
    "}\n",
    "\n",
    "# GridSearchCV model\n",
    "gs = GridSearchCV(pipe, param_grid=params, cv=10)\n",
    "gs.fit(X_train, y_train) # Fit and tune model\n",
    "\n",
    "print(\"Best Score:\",gs.best_score_) # Print Best Score\n",
    "print(\"Best Params:\",gs.best_params_) # Print Best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print Holdout Accuracy\n",
    "print(\"Holdout Accuracy:\",gs.score(X_holdout,y_holdout))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "randomforest.fit(X_train,y_train)\n",
    "randomforest.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance of this model \n",
    "\n",
    "feature_importance = pd.DataFrame({\n",
    "        'Feature':X.columns,\n",
    "        'Importance':randomforest.feature_importances_\n",
    "    })\n",
    "\n",
    "feature_importance.sort_values('Importance', ascending=False, inplace=True)\n",
    "feature_importance.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Feature importance of this model \n",
    "fig = plt.figure(figsize=(10,4))\n",
    "\n",
    "fig = sns.barplot(x='Feature', y='Importance', data=feature_importance.head(11))\n",
    "fig.set_title('Random Forest Feature Importance');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Predicting on holdout and real set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction on holdout\n",
    "pred = gs.predict(X_holdout)\n",
    "# Calculate and print R^2 and MAE for holdout\n",
    "print('R^2: ', r2_score(y_holdout, pred))\n",
    "print('MAE: ', mean_absolute_error(y_holdout, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Training and Holdout set predictions \n",
    "\n",
    "plt.figure(figsize=(12, 8))  # Figure size\n",
    "plt.subplot(1,2,1)  # Subplot in row one column one\n",
    "plt.scatter(x=y_train, y = gs.predict(X_train))\n",
    "plt.ylabel('Predicted Prices', fontsize=14) # Y-label\n",
    "plt.xlabel('True Prices', fontsize=14) # X-label\n",
    "plt.tick_params(labelsize=15) # Label size\n",
    "plt.title('Training set', fontsize=14) # Title of first subplot\n",
    "\n",
    "\n",
    "plt.subplot(1,2,2) # Subplot in row one column two\n",
    "plt.scatter(x=y_holdout, y = gs.predict(X_holdout))\n",
    "plt.ylabel('Predicted Prices', fontsize=14) # Y-label\n",
    "plt.xlabel('True Prices', fontsize=14) # X-label\n",
    "plt.tick_params(labelsize=15) # Label size\n",
    "plt.title('Holdout set', fontsize=14) # Title of first subplot\n",
    "plt.savefig(\"../Images/Train_Holdout_predictions.jpg\",bbox_inches='tight',pad_inches=.5); # Save image\n",
    "\n",
    "plt.show() # Remove text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'R^2 Score for Training: {gs.score(X_train, y_train)}')\n",
    "print(f'R^2 Score fro Holdout: {gs.score(X_holdout, y_holdout)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_test\n",
    "X_test = test_features\n",
    "\n",
    "# Predictions\n",
    "predictions_on_real_test = gs.best_estimator_.predict(X_test)\n",
    "predictions_on_real_test = np.expm1(predictions_on_real_test)\n",
    "result_on_real_test = X_test.copy()\n",
    "\n",
    "# Show results on df for predictions\n",
    "for_csv = pd.concat([test['Id'], pd.DataFrame(predictions_on_real_test, columns=['SalePrice'])], axis=1)\n",
    "for_csv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for_csv.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
